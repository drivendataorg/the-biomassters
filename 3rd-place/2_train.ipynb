{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import albumentations as A\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import segmentation_models_pytorch as smp\n",
    "import torch\n",
    "import rasterio as rio\n",
    "from pytorch_lightning import Trainer\n",
    "# from pytorch_lightning.loggers import WandbLogger\n",
    "from sklearn.model_selection import train_test_split\n",
    "from pytorch_lightning.callbacks import ModelCheckpoint, LearningRateMonitor\n",
    "import warnings\n",
    "from torchsummary import summary\n",
    "from torch.utils.data import DataLoader\n",
    "import json\n",
    "# import wandb\n",
    "from utils import calcuate_mean_std, stratify_data, freeze_encoder, BioMasstersDatasetS2S1, SentinelModel\n",
    "\n",
    "warnings.filterwarnings(\"ignore\", category=rio.errors.NotGeoreferencedWarning)\n",
    "np.set_printoptions(suppress=True)\n",
    "pd.set_option('display.float_format', lambda x: '%.2f' % x)\n",
    "torch.set_printoptions(sci_mode=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training\n",
    "* 15 models were trained using a *UNet++* architecture in combination with various encoders (e.g. *se_resnext50_32x4d* and *efficientnet-b{7,8}*) and median cloud-free composites. From the experiments, *UNet++* showed better performance as compared to other decoders (e.g *UNet*, *MANet* etc.)\n",
    "* The models were pretrained with multiple augmentations (*HorizontalFlip*, *VerticalFlip*, *RandomRotate90*, *Transpose*, *ShiftScaleRotate*), batch size of 32, *AdamW* optimizer with 0.001 initial learning rate, weight decay of 0.0001, and a *ReduceLROnPlateau* scheduler\n",
    "* *UNet++* models were optimized using a *Huber* loss to reduce the effect of outliers in the data for 200 epochs\n",
    "* To improve the performance of each *UNet++* model they were further fine-tuned (after freezing pre-trained encoder weights and removing augmentations) for another 100 epochs with batch size of 32, *AdamW* optimizer with 0.0005 initial learning rate, weight decay of 0.0001, and a *ReduceLROnPlateau* scheduler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "root_dir = os.getcwd() # Change to the folder where you stored preprocessed training data\n",
    "\n",
    "S1_CHANNELS = {'2S': 8, '2SI': 12, '3S': 12, '4S': 16, '4SI': 24, '6S': 24}\n",
    "S2_CHANNELS = {'2S': 20, '2SI': 38, '3S': 30, '4S': 40, '4SI': 48, '6S': 60}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Stratify data\n",
    "Here I split train data into train (8593 samples) and validation (96 samples) datasets. This is done in a strtatified manner based on average and standard deviation of agb values to ensure similar distributions of both datasets. \n",
    "NOTE: my original train/validation split was based on a random <code>random_state</code>, so I included it for reproducibility of the results: <code>./data/train_val_split_96_0_original.csv</code>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df = stratify_data(\n",
    "    s2_path_train=f\"{root_dir}/train_features_s2_4S\", \n",
    "    agb_path=f\"{root_dir}/train_agbm\", \n",
    "    s2_path_test=f\"{root_dir}/test_features_s2_4S\", \n",
    "    test_size=96, \n",
    "    random_state=0\n",
    ")\n",
    "df.to_csv(os.path.join(f'./data/train_val_split_96_0.csv'), index=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To reproduce the results simply read pre-computed train/validation/test splits from file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv(os.path.join(f'./data/train_val_split_96_0.csv'), dtype={\"id\": str})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we define train, validation and test sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "X_train, X_val, X_test = (df[\"id\"].loc[df[\"dataset\"] == 0].tolist(),\n",
    "                          df[\"id\"].loc[df[\"dataset\"] == 1].tolist(),\n",
    "                          df[\"id\"].loc[df[\"dataset\"] == 2].tolist())\n",
    "print(df[\"dataset\"].value_counts())\n",
    "print(\"Total Images: \", len(df))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculate mean and std for image standardization\n",
    "Here I calculate mean and standard deviation for each composite data using train dataset, which are used for data standardization. I also standardized target variable (i.e. agb) as it showed to speed up model convergence."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "mean_agb, std_agb = calcuate_mean_std(image_dir=f\"{root_dir}/train_agbm\", train_set=X_train, percent=100, channels=1, \n",
    "                                      nodata=None, data='agbm', log_scale=False)\n",
    "\n",
    "mean, std = {}, {}\n",
    "for SUFFIX in ['2S', '2SI', '3S', '4S', '4SI', '6S']:\n",
    "\n",
    "    S2_PATH = f\"{os.path.join(root_dir, f'train_features_s2_{SUFFIX}')}\"\n",
    "    S1_PATH = f\"{os.path.join(root_dir, f'train_features_s1_{SUFFIX}')}\"\n",
    "\n",
    "    mean_s2, std_s2 = calcuate_mean_std(image_dir=S2_PATH, train_set=X_train, percent=5, channels=S2_CHANNELS[SUFFIX], \n",
    "                                              nodata=0, data='S2', log_scale=False)\n",
    "    mean_s1, std_s1 = calcuate_mean_std(image_dir=S1_PATH, train_set=X_train,  percent=5, channels=S1_CHANNELS[SUFFIX], \n",
    "                                              nodata=None, data='S1', log_scale=False)\n",
    "\n",
    "    mean[SUFFIX] = mean_s2 + mean_s1\n",
    "    std[SUFFIX] = mean_s1 + std_s1\n",
    "    \n",
    "with open('./data/mean.json', 'w') as f:\n",
    "    json.dump(mean, f)\n",
    "with open('./data/std.json', 'w') as f:\n",
    "    json.dump(std, f)\n",
    "with open('./data/mean_agb.json', 'w') as f:\n",
    "    json.dump(mean_agb, f)\n",
    "with open('./data/std_agb.json', 'w') as f:\n",
    "    json.dump(std_agb, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can skip previous step and read pre-calculated values from the json files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "f = open('./data/mean.json')\n",
    "mean = json.load(f)\n",
    "f = open('./data/std.json')\n",
    "std = json.load(f)\n",
    "f = open('./data/mean_agb.json')\n",
    "mean_agb = json.load(f)\n",
    "f = open('./data/std_agb.json')\n",
    "std_agb = json.load(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Making sure we can train on GPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(torch.cuda.is_available())\n",
    "# Empty cache\n",
    "torch.cuda.empty_cache()\n",
    "print(torch.version.cuda)\n",
    "torch.backends.cudnn.benchmark = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training strategy\n",
    "Overall I trained 15 *UNet++* models with different encoders accessible in [segmentation_models_pytorch](https://github.com/qubvel/segmentation_models.pytorch). Each of the models was trained in a 2-stage manner:\n",
    "1) Base model traing using *imagenet* or *advprop* pre-training for 200 epochs\n",
    "2) Fine-tuning of the base model after freezing encoder weights for another 100 epochs. Here I provided paths to the weights of the pre-trained models, so replace them if planning to train from scratch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Base model setup\n",
    "batch_size: 32/\n",
    "epochs: 200/\n",
    "learting_rate: 0.001/\n",
    "weight_decay: 0.0001/\n",
    "augmentations: HorizontalFlip(), VerticalFlip(), RandomRotate90(), Transpose(), ShiftScaleRotate()/\n",
    "scheduler: ReduceLROnPlateau()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def train_base_model(suffix, encoder_name, encoder_weights, decoder_attention_type):\n",
    "    # wandb.finish()    \n",
    "    \n",
    "    train_set = BioMasstersDatasetS2S1(s2_path=f\"{root_dir}/train_features_s2_{suffix}\",\n",
    "                                       s1_path=f\"{root_dir}/train_features_s1_{suffix}\",\n",
    "                                       agb_path=f\"{root_dir}/train_agbm\", X=X_train, mean=mean[suffix], std=std[suffix], \n",
    "                                       mean_agb=mean_agb, std_agb=std_agb, \n",
    "                                       transform=A.Compose([A.HorizontalFlip(), A.VerticalFlip(), \n",
    "                                                            A.RandomRotate90(), A.Transpose(), A.ShiftScaleRotate()]))\n",
    "\n",
    "    val_set = BioMasstersDatasetS2S1(s2_path=f\"{root_dir}/train_features_s2_{suffix}\",\n",
    "                                     s1_path=f\"{root_dir}/train_features_s1_{suffix}\",\n",
    "                                     agb_path=f\"{root_dir}/train_agbm\", X=X_val, mean=mean[suffix], std=std[suffix], \n",
    "                                     mean_agb=mean_agb, std_agb=std_agb, transform=None)\n",
    "\n",
    "    train_loader = DataLoader(train_set, shuffle=True, batch_size=8, num_workers=8, pin_memory=True)\n",
    "    \n",
    "    val_loader = DataLoader(val_set, shuffle=False, batch_size=8, num_workers=8, pin_memory=True)\n",
    "\n",
    "    model = smp.UnetPlusPlus(encoder_name=encoder_name, encoder_weights=encoder_weights, \n",
    "                             decoder_attention_type=decoder_attention_type,\n",
    "                             in_channels=S2_CHANNELS[suffix]+S1_CHANNELS[suffix], classes=1, activation=None)\n",
    "\n",
    "    s2s1_model = SentinelModel(model, mean_agb=mean_agb, std_agb=std_agb, lr=0.001, wd=0.0001)\n",
    "\n",
    "    # summary(s2s1_model.cuda(), (S2_CHANNELS[SUFFIX]+S1_CHANNELS[SUFFIX], 256, 256)) \n",
    "\n",
    "    # wandb_logger = WandbLogger(save_dir=f'./models', name=f'{encoder_name}_{suffix}_{decoder_attention_type}', \n",
    "    #                            project=f'{encoder_name}_{suffix}_{decoder_attention_type}')\n",
    "\n",
    "    ## Define a trainer and start training:\n",
    "    on_best_valid_loss = ModelCheckpoint(filename=\"{epoch}-{valid/loss}\", mode='min', save_last=True,\n",
    "                                         monitor='valid/loss', save_top_k=2)\n",
    "    on_best_valid_rmse = ModelCheckpoint(filename=\"{epoch}-{valid/rmse}\", mode='min', save_last=True,\n",
    "                                         monitor='valid/rmse', save_top_k=2)\n",
    "    lr_monitor = LearningRateMonitor(logging_interval='epoch')\n",
    "    checkpoint_callback = [on_best_valid_loss, on_best_valid_rmse, lr_monitor]\n",
    "\n",
    "    # Initialize a trainer\n",
    "    trainer = Trainer(precision=16, accelerator=\"gpu\", devices=1, max_epochs=200, \n",
    "                      # logger=[wandb_logger], \n",
    "                      callbacks=checkpoint_callback)\n",
    "    # Train the model ⚡\n",
    "    trainer.fit(s2s1_model, train_dataloaders=train_loader, val_dataloaders=val_loader)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fine-tuned model setup\n",
    "batch_size: 32/\n",
    "epochs: 100/\n",
    "learting_rate: 0.0005/\n",
    "weight_decay: 0.0001/\n",
    "augmentations: None/\n",
    "scheduler: ReduceLROnPlateau()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def train_finetuned_model(checkpoint_path, suffix, encoder_name, decoder_attention_type):\n",
    "    # wandb.finish()\n",
    "\n",
    "    train_set = BioMasstersDatasetS2S1(s2_path=f\"{root_dir}/train_features_s2_{suffix}\",\n",
    "                                       s1_path=f\"{root_dir}/train_features_s1_{suffix}\",\n",
    "                                       agb_path=f\"{root_dir}/train_agbm\", X=X_train, mean=mean[suffix], std=std[suffix], \n",
    "                                       mean_agb=mean_agb, std_agb=std_agb, transform=None)\n",
    "\n",
    "    val_set = BioMasstersDatasetS2S1(s2_path=f\"{root_dir}/train_features_s2_{suffix}\",\n",
    "                                     s1_path=f\"{root_dir}/train_features_s1_{suffix}\",\n",
    "                                     agb_path=f\"{root_dir}/train_agbm\", X=X_val, mean=mean[suffix], std=std[suffix], \n",
    "                                     mean_agb=mean_agb, std_agb=std_agb, transform=None)\n",
    "\n",
    "    train_loader = DataLoader(train_set, shuffle=True, batch_size=8, num_workers=8, pin_memory=True)\n",
    "\n",
    "    val_loader = DataLoader(val_set, shuffle=False, batch_size=8, num_workers=8, pin_memory=True)\n",
    "\n",
    "    model = smp.UnetPlusPlus(encoder_name=encoder_name, decoder_attention_type=decoder_attention_type,\n",
    "                             in_channels=S2_CHANNELS[suffix]+S1_CHANNELS[suffix], classes=1, activation=None)\n",
    "\n",
    "    freeze_encoder(model)\n",
    "\n",
    "    s2s1_model = SentinelModel.load_from_checkpoint(model=model, checkpoint_path=checkpoint_path, \n",
    "                                                    mean_agb=mean_agb, std_agb=std_agb,\n",
    "                                                    lr=0.0005, wd=0.0001)\n",
    "\n",
    "\n",
    "    # summary(s2s1_model.cuda(), (S2_CHANNELS[SUFFIX]+S1_CHANNELS[SUFFIX], 256, 256)) \n",
    "\n",
    "\n",
    "#     wandb_logger = WandbLogger(save_dir=f'./models', name=f'{encoder_name}_{suffix}_{decoder_attention_type}', \n",
    "#                                project=f'{encoder_name}_{suffix}_{decoder_attention_type}')\n",
    "\n",
    "    ## Define a trainer and start training:\n",
    "    on_best_valid_loss = ModelCheckpoint(filename=\"{epoch}-{valid/loss}\", mode='min', save_last=True,\n",
    "                                         monitor='valid/loss', save_top_k=2)\n",
    "    on_best_valid_rmse = ModelCheckpoint(filename=\"{epoch}-{valid/rmse}\", mode='min', save_last=True,\n",
    "                                         monitor='valid/rmse', save_top_k=2)\n",
    "    lr_monitor = LearningRateMonitor(logging_interval='epoch')\n",
    "    checkpoint_callback = [on_best_valid_loss, on_best_valid_rmse, lr_monitor]\n",
    "\n",
    "    # Initialize a trainer\n",
    "    trainer = Trainer(precision=16, accelerator=\"gpu\", devices=1, max_epochs=100, \n",
    "                      # logger=[wandb_logger], \n",
    "                      callbacks=checkpoint_callback)\n",
    "    # Train the model ⚡\n",
    "    trainer.fit(s2s1_model, train_dataloaders=train_loader, val_dataloaders=val_loader)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train and fine-tune model #1\n",
    "Composite: 4S/\n",
    "Decoder: UNet++/\n",
    "Decoder attention type: None/\n",
    "Encoder: se_resnext50_32x4d/\n",
    "Encoder pre-training: imagenet"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "The certificate for the site to download model weights might be expired. You can use the code below to continue on by creating an unverified context, be aware of the security risks.\n",
    "```\n",
    "import ssl\n",
    "ssl._create_default_https_context = ssl._create_unverified_context\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import ssl\n",
    "ssl._create_default_https_context = ssl._create_unverified_context"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "if __name__ == '__main__':\n",
    "    train_base_model('4S', \"se_resnext50_32x4d\", \"imagenet\", None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == '__main__':\n",
    "    checkpoint_path = r'./models/se_resnext50_32x4d_4S_None/1on9ti36/checkpoints/loss=0.07419885694980621.ckpt'\n",
    "    train_finetuned_model(checkpoint_path, '4S', \"se_resnext50_32x4d\", None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train and fine-tune model #2\n",
    "Composite: 4S/\n",
    "Decoder: UNet++/\n",
    "Decoder attention type: None/\n",
    "Encoder: se_resnext101_32x4d/\n",
    "Encoder pre-training: imagenet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == '__main__':\n",
    "    train_base_model('4S', \"se_resnext101_32x4d\", \"imagenet\", None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == '__main__':\n",
    "    checkpoint_path = r'./models/se_resnext101_32x4d_4S_None/39jj4bmx/checkpoints/loss=0.07529886066913605.ckpt'\n",
    "    train_finetuned_model(checkpoint_path, '4S', \"se_resnext101_32x4d\", None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train and fine-tune model #3\n",
    "Composite: 4S/\n",
    "Decoder: UNet++/\n",
    "Decoder attention type: scse/\n",
    "Encoder: se_resnext50_32x4d/\n",
    "Encoder pre-training: imagenet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == '__main__':\n",
    "    train_base_model('4S', \"se_resnext50_32x4d\", \"imagenet\", \"scse\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == '__main__':\n",
    "    checkpoint_path = r'./models/se_resnext50_32x4d_4S_scse/v0pd76d5/checkpoints/rmse=31.418827056884766.ckpt'\n",
    "    train_finetuned_model(checkpoint_path, '4S', \"se_resnext50_32x4d\", \"scse\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train and fine-tune model #4\n",
    "Composite: 3S/\n",
    "Decoder: UNet++/\n",
    "Decoder attention type: scse/\n",
    "Encoder: se_resnext50_32x4d/\n",
    "Encoder pre-training: imagenet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == '__main__':\n",
    "    train_base_model('3S', \"se_resnext50_32x4d\", \"imagenet\", \"scse\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == '__main__':\n",
    "    checkpoint_path = r'./models/se_resnext50_32x4d_3S_scse/92gj2lnf/checkpoints/rmse=31.44633674621582.ckpt'\n",
    "    train_finetuned_model(checkpoint_path, '3S', \"se_resnext50_32x4d\", \"scse\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train and fine-tune model #5\n",
    "Composite: 4S/\n",
    "Decoder: UNet++/\n",
    "Decoder attention type: None/\n",
    "Encoder: efficientnet-b6/\n",
    "Encoder pre-training: imagenet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == '__main__':\n",
    "    train_base_model('4S', \"efficientnet-b6\", \"imagenet\", None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == '__main__':\n",
    "    checkpoint_path = r'./models/efficientnet-b6_4S_None/2h56bi5o/checkpoints/rmse=31.456979751586914.ckpt'\n",
    "    train_finetuned_model(checkpoint_path, '4S', \"efficientnet-b6\", None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train and fine-tune model #6\n",
    "Composite: 4SI/\n",
    "Decoder: UNet++/\n",
    "Decoder attention type: None/\n",
    "Encoder: efficientnet-b5/\n",
    "Encoder pre-training: imagenet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == '__main__':\n",
    "    train_base_model('4SI', \"efficientnet-b5\", \"imagenet\", None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == '__main__':\n",
    "    checkpoint_path = r'./models/efficientnet-b5_4SI_None/2o168bz4/checkpoints/loss=0.07675273716449738.ckpt'\n",
    "    train_finetuned_model(checkpoint_path, '4SI', \"efficientnet-b5\", None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train and fine-tune model #7\n",
    "Composite: 4S/\n",
    "Decoder: UNet++/\n",
    "Decoder attention type: None/\n",
    "Encoder: xception/\n",
    "Encoder pre-training: imagenet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == '__main__':\n",
    "    train_base_model('4S', \"xception\", \"imagenet\", None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == '__main__':\n",
    "    checkpoint_path = r'./models/xception_4S_None/2vupnzea/checkpoints/loss=0.07764090597629547.ckpt'\n",
    "    train_finetuned_model(checkpoint_path, '4S', \"xception\", None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train and fine-tune model #8\n",
    "Composite: 2SI/\n",
    "Decoder: UNet++/\n",
    "Decoder attention type: None/\n",
    "Encoder: se_resnext50_32x4d/\n",
    "Encoder pre-training: imagenet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == '__main__':\n",
    "    train_base_model('2SI', \"se_resnext50_32x4d\", \"imagenet\", None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == '__main__':\n",
    "    checkpoint_path = r'./models/se_resnext50_32x4d_2SI_None/2hd4nj2v/checkpoints/loss=0.07711037248373032.ckpt'\n",
    "    train_finetuned_model(checkpoint_path, '2SI', \"se_resnext50_32x4d\", None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train and fine-tune model #9\n",
    "Composite: 2S/\n",
    "Decoder: UNet++/\n",
    "Decoder attention type: None/\n",
    "Encoder: se_resnext50_32x4d/\n",
    "Encoder pre-training: imagenet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == '__main__':\n",
    "    train_base_model('2S', \"se_resnext50_32x4d\", \"imagenet\", None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == '__main__':\n",
    "    checkpoint_path = r'./models/se_resnext50_32x4d_2S_None/2xax1i19/checkpoints/rmse=31.860191345214844.ckpt'\n",
    "    train_finetuned_model(checkpoint_path, '2S', \"se_resnext50_32x4d\", None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train and fine-tune model #10\n",
    "Composite: 6S/\n",
    "Decoder: UNet++/\n",
    "Decoder attention type: None/\n",
    "Encoder: timm-efficientnet-b7/\n",
    "Encoder pre-training: advprop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == '__main__':\n",
    "    train_base_model('6S', \"timm-efficientnet-b7\", \"advprop\", None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == '__main__':\n",
    "    checkpoint_path = r'./models/timm-efficientnet-b7_6S_None/yitdzdeu/checkpoints/loss=0.07400769740343094.ckpt'\n",
    "    train_finetuned_model(checkpoint_path, '6S', \"timm-efficientnet-b7\", None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train and fine-tune model #11\n",
    "Composite: 6S/\n",
    "Decoder: UNet++/\n",
    "Decoder attention type: None/\n",
    "Encoder: timm-efficientnet-b8/\n",
    "Encoder pre-training: advprop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == '__main__':\n",
    "    train_base_model('6S', \"timm-efficientnet-b8\", \"advprop\", None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == '__main__':\n",
    "    checkpoint_path = r'./models/timm-efficientnet-b8_6S_None/vnyxfdjt/checkpoints/loss=0.07360904663801193.ckpt'\n",
    "    train_finetuned_model(checkpoint_path, '6S', \"timm-efficientnet-b8\", None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train and fine-tune model #12\n",
    "Composite: 6S/\n",
    "Decoder: UNet++/\n",
    "Decoder attention type: None/\n",
    "Encoder: se_resnext50_32x4d/\n",
    "Encoder pre-training: imagenet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == '__main__':\n",
    "    train_base_model('6S', \"se_resnext50_32x4d\", \"imagenet\", None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == '__main__':\n",
    "    checkpoint_path = r'./models/se_resnext50_32x4d_6S_None/qji032p2/checkpoints/loss=0.07499314099550247.ckpt'\n",
    "    train_finetuned_model(checkpoint_path, '6S', \"se_resnext50_32x4d\", None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train and fine-tune model #13\n",
    "Composite: 4S/\n",
    "Decoder: UNet++/\n",
    "Decoder attention type: None/\n",
    "Encoder: timm-efficientnet-b8/\n",
    "Encoder pre-training: advprop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == '__main__':\n",
    "    train_base_model('4S', \"timm-efficientnet-b8\", \"advprop\", None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == '__main__':\n",
    "    checkpoint_path = r'./models/timm-efficientnet-b8_4S_None/66ucn90m/checkpoints/loss=0.0746900737285614.ckpt'\n",
    "    train_finetuned_model(checkpoint_path, '4S', \"timm-efficientnet-b8\", None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train and fine-tune model #14\n",
    "Composite: 4SI/\n",
    "Decoder: UNet++/\n",
    "Decoder attention type: None/\n",
    "Encoder: efficientnet-b7/\n",
    "Encoder pre-training: imagenet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == '__main__':\n",
    "    train_base_model('4SI', \"efficientnet-b7\", \"imagenet\", None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == '__main__':\n",
    "    checkpoint_path = r'./models/efficientnet-b7_4SI_None/fkk9ny5j/checkpoints/loss=0.07656403630971909.ckpt'\n",
    "    train_finetuned_model(checkpoint_path, '4SI', \"efficientnet-b7\", None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train and fine-tune model #15\n",
    "Composite: 4S/\n",
    "Decoder: UNet++/\n",
    "Decoder attention type: None/\n",
    "Encoder: senet154/\n",
    "Encoder pre-training: imagenet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == '__main__':\n",
    "    train_base_model('4S', \"senet154\", \"imagenet\", None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == '__main__':\n",
    "    checkpoint_path = r'./models/senet154_4S_None/j5fkjqvs/checkpoints/loss=0.07581867277622223.ckpt'\n",
    "    train_finetuned_model(checkpoint_path, '4S', \"senet154\", None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
